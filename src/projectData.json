{
  "projects": [
    {
      "id": 1,
      "title": "ideo colab",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/c311po-cover1.jpg",
      "heroAlt": "Image of an iPhone featuring the virtual assistant in Facebook Messenger app.",
      "description": "CoLab is IDEO’s R&D network bringing together disruptors from industry and academia to understand and shape how emerging technologies will affect the future.",
      "problem": "How might we recognize changes in public sentiment to optimize city administration?",
      "solution": [
        {"id": 0, "paragraph": "C311-PO is a virtual assistant for reporting non emergency issues in the city of Boston, integrated in Facebook Messenger platform."},
        {"id": 1, "paragraph": "In this third design sprint on communal artificial intelligence we investigated smart cities and how AI might further the interests of civilians and the city administration. Eager to use some machine learning models we looked at large unused datasets from existing city infrastructures. The 311 calls dataset (non emergency issues) was most exciting as Boston had improved their reporting infrastructure with a mobile app combined with thorough activity on the platform from all the different city department involved."},
        {"id": 2, "paragraph": "First we searched for ways to increase efficiency of the current infrastructure. We interviewed key managers of the system and noticed near optimum efficiency - in fact we reported a pothole and it was fixed the next day. We explored ways to predict issues when and where they are most likely to occur without significant results. Finally, the idea of civilian happiness appeared as an application of communal AI. How might we measure what people care most about? Were there issues civilians felt more strongly about? Hence we took on to build a virtual assistant to handle what the current mobile app was doing."},
        {"id": 3, "paragraph": "The reason behind this choice is to create a words dialogue between the city administration and its inhabitants. Civilians can describe the issue, send their location and snap a picture with their phone all through a Facebook Messenger conversation. However, we used the text from their conversations as an input to the IBM Watson API and get a sentiment analysis index (how positive or negative the word they chose were etc.) By synthesizing the data we were able to display a general sentiment of the conversation and with more data we could get an overall sentiment of the city. Additionally, we used Twitter data (civilians voice their concerns about non emergency using the hashtag #BOS311) to categorize sentiment based on specific issues."}
      ],
      "addMedia": [
        {"id": 0, "url": "https://s3-us-west-2.amazonaws.com/mypf/images/c311po-2.jpg", "caption": "Data visualization of 311 reports on Twitter"}
      ],
      "conclusion": "This sprint unveiled a new aspect of artificial intelligence we didn’t expect such as the use of a sentimental component to augment conversational user interfaces. Indeed, most currently available experiences with conversational user interfaces solely relies on natural language processing, deep neural networks able to categorize our intentions based on the words we use. However, sentiment is a dimension which hasn’t been explored in depth within the scope of these experiences. How might adding a sentiment index to an interface improve the experience? From applications in customer service to optimization of existing systems and better feedback loops or simply better chatbots experiences. Lastly, we explored what it entailed to replace a mobile app with a chat interface. We presented our prototype to city officials and understood the complexity of adding another layer of software infrastructure to an already extremely complex software + humans infrastructure. Such system would need to be redesigned from the ground up for seamless results.",
      "skills": "design thinking, node js, conversational user interface, natural language processing, javascript, wit.ai, facebook messenger platform, ibm watson sentiment analysis api.",
      "team": [
        {"id": 0, "name": "Lisa Tacoronte", "from": "MIT Sloan"},
        {"id": 1, "name": "Sara Remsen", "from": "MIT Media Lab"},
        {"id": 2, "name": "Kyle Scherer", "from": "Nasdaq"}
      ],
      "date": "01.17"
    },
    {
      "id": 2,
      "title": "ideo colab",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/kaitt1.jpg",
      "heroAlt": "Image of a life size modelized car interior.",
      "description": "CoLab is IDEO’s R&D network bringing together disruptors from industry and academia to understand and shape how emerging technologies will affect the future.",
      "problem": "How might we redesign priority in a system of autonomous vehicles?",
      "solution": [
        {"id": 0, "paragraph": "KAITT is a voice controlled virtual assistant designed to handle emergencies in autonomous vehicles systems. It is able to detect, assess and rank the level of emergency of a given situation and gain priority on the road to drive passengers as fast as possible to their destination."},
        {"id": 1, "paragraph": "Within the realm of communal artificial intelligence this brief brought me to the space of mobility and autonomous vehicles. While exploring how artificial intelligence would further the interests of a community we kept coming back to scarcity and priorities. How might AI help coordinate shared resources ranging from water to public transportation axes to negotiate and optimize individual priorities in a network? As more autonomous vehicles solutions are being tested, we wondered how computers might handle the different priorities and needs of the passengers. What if any autonomous vehicle could become an ambulance? Thus we imagined KAITT, an embedded assistant interface for handling emergencies."},
        {"id": 2, "paragraph": "We ventured in a very complex system with multiple problems intelligent algorithms could help solve. First, how might we categorize passenger intent? We prototyped this system with a Google Home device paired with a natural language processing API – API.AI – able to parse the words and categorize user intents based on the words used to describe the situation. A more advanced system would combine it with sentiment analysis and computer vision to assess facial expression and categorize the intent with truth and accuracy. Second, how might vehicles exhibit responsive, coordinated behavior without central control? In fact, each vehicle is its own independent system hence we had to figure out how they might make way for higher priority vehicles?"},
        {"id": 3, "paragraph": "We went on the field interview firefighters from the Cambridge station in order to understand their experience taking priority on the road and assessing emergency situations. Furthermore we looked into biological system behaviors especially insects, birds and swarming behaviors. Vehicles are aware of their immediate surroundings through sensors and have an idea of circulation at a given location thanks to navigation systems. We prototyped these behaviors in Processing applying Daniel Shiffman’s work on independent agents, vectors and paths following which related considerably to the behaviors of autonomous vehicles on a road. By giving a precise set of rules to each agent they were able to behave in respect to each others without explicit communication. In addition, we built a physical model of a vehicle interior to create a more realistic experience for user testing of the voice interface."}
      ],
      "addMedia": [
        {"id": "0", "url": "https://s3-us-west-2.amazonaws.com/mypf/images/kaitt-2.gif", "caption": "Modelizing independent agents moving along a path on Processing"},
        {"id": "1", "url": "https://s3-us-west-2.amazonaws.com/mypf/images/kaitt-3.gif", "caption": "Swarm model on Processing, same as above each shape has an algorithm defining how to behave based on the behaviors of their neighbors"}
      ],
      "conclusion": "This deep dive into autonomous vehicles systems was very insightful to explain how different levels of machine intelligence can interact to achieve a complex outcome. Furthermore, prioritization on the road can be achieved through group behaviors of independent agents working together to achieve an outcome on a micro level. Autonomous vehicles will have great impact on ambulance systems. In fact, a 15mn Ambulance trip can cost up to $2,000 and emergency patients will sometime call an Uber over 911. This user experience is also a great use case for voice controlled virtual assistants and we can imagine a virtual copilot as an interface to communicate with autonomous vehicles with very little friction for the passengers. We also envision visual signifiers to warn other vehicles while some are still handled by human drivers. Lastly such system would not achieve maximum efficiency without a fully automated transportation grid.",
      "skills": "design thinking, javascript, node js, google home, natural language processing, api.ai, processing, socket.io.",
      "team": [
        {"id": 0, "name": "Lisa Tacoronte", "from": "MIT Sloan"},
        {"id": 1, "name": "Sara Remsen", "from": "MIT Media Lab"}
      ],
      "date": "01.17"
    },
    {
      "id": 3,
      "title": "ideo colab",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/contexta1.jpg",
      "heroAlt": "Image of an Amazon Echo dot on a table.",
      "description": "CoLab is IDEO’s R&D network bringing together disruptors from industry and academia to understand and shape how emerging technologies will affect the future.",
      "problem": "How might we use artificial intelligence to create a personalized learning experience?",
      "solution": [
        {"id": 0, "paragraph": "Contexta is a virtual homework assistant on Amazon Echo platform. It provides personalized, adaptive, contextualized homework based on location, current events and user input."},
        {"id": 1, "paragraph": "Our brief for this design sprint was the following: How might we ensure that AIs represent our collective interests as a society? This was extremely broad and we circled back and forth to identify personas most suited to design for. We were curious about furthering the interests of a class of high school students and decided to leverage machine intelligence to create adaptive curriculums."},
        {"id": 2, "paragraph":"There was two interesting aspects to it: evolution based on progress from the student and based on current economical and societal context (demand in the workforce etc.) Therefore we imagined a curriculum adaptive to those different parameters. In order to create an ‘instructor to student’ experience we prototyped the AI system with a voice controlled interface using an Echo Dot. We scripted conversations directly on the Amazon platform (unfortunately pretty limited without basic natural language processing integration.)"}
      ],
      "addMedia": [
        {"id": "0", "url": "https://s3-us-west-2.amazonaws.com/mypf/images/contexta-2.png", "caption": "Scripting conversations to prototype the homework assistant"}
      ],
      "conclusion": "The machine learning system was too complex to prototype on a software level nevertheless prototyping the experience was insightful. As part of the lessons learned working with this AI concept we realized in order to eventually achieve such an experience would require to strip down the machine learning model to execute simpler tasks at first such as recommending relevant curriculum and difficulty. With more progress in natural language processing it might be possible in the future to actually generate exercises in fields such as history, language, literature etc. Moreover machine learning algorithms could become biased as they grow and create gaps in education from one community to another. Lastly, the digital infrastructure required would be way more advanced than we currently have. One can imagine a decentralized, permanent knowledge database with a merkle tree architecture to evolve without ever deleting the past.",
      "skills": "design thinking, web, javascript, venture design, amazon echo, alexa skills platform, artificial intelligence, prototyping.",
      "team": [
        {"id": 0, "name": "Lisa Tacoronte", "from": "MIT Sloan"},
        {"id": 1, "name": "Sara Remsen", "from": "MIT Media Lab"}
      ],
      "date": "01.17"
    },
    {
      "id": 4,
      "title": "sounditure",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/sounditure1.jpg",
      "heroAlt": "Image of Autodesk Fusion 360 software interface with a 3D model of a table.",
      "description": "Sounditure is an online platform for design and manufacturing of custom furniture based on audio data from your favorite songs.",
      "problem": "How might we generate physical representation of sound?",
      "solution": [
        {"id": 0, "paragraph": "This project was made during a 24h hackathon at MIT. I didn’t have any predetermined idea so I focused on building a team of other attendants with diverse backgrounds and talents. After an ice breaker we had a very long brainstorming before we could figure out something everyone agreed to work on."},
        {"id": 1, "paragraph": "This way we looked at how to represent audio features on a physical level. Using Spotify’s open REST API we extracted audio features of specified tracks then used the new Autodesk Fusion 360 API to import the audio data and generate 3D models. In addition we looked at use cases in the furniture market and how the technology might be applied to reinvent the furniture purchase experience."}
      ],
      "addMedia": [
        {"id": 0, "url":"https://s3-us-west-2.amazonaws.com/mypf/images/sounditure.jpg", "caption": "This project won us the Autodesk prize at MIT Hacking Arts 2016!"}
      ],
      "conclusion": "For lack of time we were not able to develop a full functioning version of the platform. Instead we designed each aspect and built a strong business case. We were selected as winners of the Autodesk Prize at MIT Hacking Arts. Although some of us were curious to get user data and explore go to market strategies, geographic distance and schedules gradually split the team and dissolved the effort.",
      "skills": "Web, Prototyping, Design Thinking",
      "team": [
        {"id": 0, "name":"Kumaran Chanthrakumar", "from": "University of Illinois at Urbana-Champaign"},
        {"id": 1, "name":"Leyla Novini", "from": "Parsons School of Design"},
        {"id": 2, "name":"Jakub Florkiewicz", "from": "Harvard Business School"},
        {"id": 3, "name":"Alyssa Gerasimoff", "from": "Rhode Island School of Design"}
      ],
      "links": [
        {"id": 0, "url":"http://hackingarts.com/news-1/", "name": "Read on Hacking Arts Website"}
      ],
      "date": "11.16"
    },
    {
      "id": 5,
      "title": "squid",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/squid1.jpg",
      "heroAlt": "Image of wireframes featuring the Facebook Messenger interface in conversations with Squid.",
      "description": "Squid is a virtual assistant for concert recommendation and ticket purchase inside Facebook Messenger app.",
      "problem": "How might we design a seamless concert ticketing experience?",
      "solution": [
        {"id": 0, "paragraph": "This project developed over a 5 months period with financial support from an angel investor and Berklee ICE. When the Facebook Messenger platform opened and after frustrating personal experiences with ticket purchases, we saw the opportunity of simplifying ticket discovery and purchase via a chat interface. In fact, current ticketing platforms such as Ticketmaster or Axs are slow and complicated without great mobile first experiences forcing third party apps such as Songkick and Bandsintown to appear. A seamless experience would require a complete redesign."},
        {"id": 1, "paragraph": "We leveraged Messenger platform functionalities such as location, quick replies, template cards and integrated payment system to create a fluid experience. We first build a small script to identify the users’ favorite artists playing in their geographic area. We also implemented an integrated ticket query via Ticketmaster followed by the option to finish the purchase. As our friends started using it we gradually added features such as concert recommendations based on influent music publications and search of similar artists etc. Through the development I got to develop stronger backend Javascript skills using complex concepts such as asynchronous promises to connect all the different APIs together smoothly."}
      ],
      "addMedia": [
        {"id": 0, "url":"https://s3-us-west-2.amazonaws.com/mypf/images/squid.gif", "caption": "Animation of the user experience to prototype the ideal ticket purchase flow"}
      ],
      "conclusion": "The venture side of the project gradually developed as our friends were gaining interest and became beta users. We looked into monetization options but we weren’t able to prototype any without requiring greater infrastructure or deals with major ticket sellers. Hence we approached VCs and other angel investors who showed a great deal of curiosity towards chatbots at the time. In fact we were able to arrange a dozen of meetings most notably with Bessemer VP partner Kent Bennett who gave a huge amount of insight on our potential markets. It turns out this case study was still very niche (our friends are college students/ music nerds). Nevertheless, it was probably one of the best lesson in building the perfect pitch deck and investor pitch. We also connected with one of the Napster cofounders - John Fanning - who loved the concept and offered to help raise a greater seed round however we didn’t pursue as he was pushing us towards usage in sports and other industries we had no real interest for.",
      "skills": "web, node js, javascript, prototyping, sketch, natural language processing, wit.ai, messenger platform, spotify api, ticketmaster api, facebook api, google maps api, postgresql, pitch deck, business development",
      "team": [
        {"id":0, "name": "Dantino Camuto", "from": "Imperial College London"}
      ],
      "date": "07.16"
    },
    {
      "id": 6,
      "title": "bandpass",
      "heroAlt": "Image of different wireframes of an ecommerce mobile app.",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/bandpass.jpg",
      "description": "Bandpass originally started as an app to create interactive (audience controlled) visuals for live concerts using biometric data and wearable technology. It then pivoted towards a small ecommerce platform for real time merch sales during concerts.",
      "problem": "How might we design an interactive concert experience?",
      "solution": [
        {"id": 0, "paragraph": "As an early adopter of wearable technology (he is a big fan of Nike’s devices) Alexander had a vision of his audience controlling the visuals – such as light and motion graphics – of his shows with their biometric and motion data recorded by wearable sensors. I joined this vision during a design thinking class at Berklee and IDEO. We designed mockups of the experience and followed a very iterative approach through various user interviews. We simulated graphic animations in Processing and shifted parameters manually. As we got selected by an IDEO jury to receive resources from Berklee ICE (call this a mini incubator) we were able spending more time getting user feedback."},
        {"id": 1, "paragraph": "This approach allowed us to discover members of the audience did not necessarily wish to take an active role during live music experiences. As data refuted our first hypothesis, we looked at other ways to create audience/artist interactions during live concerts. We imagined a marketplace through which members of the audience could tip, purchase items and interact with the performing artist in order to customize their own VIP experience. We prototyped versions with a bidding functionality or with social purpose and charity integrations."}
      ],
      "conclusion": "We were able to spend a lot of time on this project (probably too much) thanks to financial support from Berklee ICE. However Alexander started this project with a vision of building and scaling a business first whereas I followed a research/ learning angle and loved exploring the different technologies involved. The project ended over this misalignment.",
      "skills": "design thinking, prototyping, processing, adobe photoshop, adobe illustrator",
      "team": [
        {"id":0 , "name": "Alexander Bercow", "from": "DJ/Musician"}
      ],
      "date": "05.15"
    },
    {
      "id": 7,
      "title": "the open music initiative",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/openmusic.jpg",
      "heroAlt": "Image of visuals created for OMI marketing purposes.",
      "description": "The Open Music Initiative is a global non profit and open source project aimed at helping musicians get compensated more fairly by increasing interoperability between all the parties of the music industry. The project has many parties and dimensions and was thus separated in different working groups. I followed my interest in digital identity and joined the Identity, Security & Audit Services group.",
      "problem": "How might we identify owners of creative works and verify their identity?",
      "solution": [
        {"id": 0, "paragraph": "The first part of the solution we proposed consists in API specifications for minimum interoperability between the different parties of the music industry."}
      ],
      "conclusion": "This project is open source and I am excited to maintain regular design contribution as the API evolves over time and prototype some implementations.",
      "skills": "design thinking, music business",
      "team": [
        {"id": 0, "name": "Berklee ICE", "from": ""},
        {"id": 1, "name": "The Open Music Initiative community", "from": ""}
      ],
      "date": "03.17"
    },
    {
      "id": 8,
      "title": "making of this portfolio website",
      "problem": "How might we organize and showcase projects online while learning new skills?",
      "hero": "https://s3-us-west-2.amazonaws.com/mypf/images/portfolio.jpg",
      "heroAlt": "Image of physical wireframes of the website made with post it notes.",
      "description": "This portfolio is a static React website designed for mobile first featuring server rendering",
      "solution": [
        {"id": 0, "paragraph": "As I achieved increasingly cool projects and for professional development reasons I felt the need to have an online presence showcasing my work. At home for two weeks I sat down and solved this like a design sprint. I could have simply used some of the portfolio services out there but wanted to hone my front end web development skills so I spent some time browsing the web for some cool tools to learn. I knew Node JS and ejs template rendering and was looking for an intuitive framework to pair with. I had heard of React though it seemed scary and too big to master through a two weeks project. However, after reading the docs and watching some videos on YouTube it didn’t seem scary anymore and I went for it."},
        {"id": 1, "paragraph": "First, I made a physical layout of it using post-its to represent the different reusable components. Then I went to Sketch and stripped down the layout to its bare essentials and to fit a mobile phone display. I used sass as it was more intuitive coming from a javascript perspective (I hate css.) I built the full layout for mobile screen size and enabled server render first. I read tons of documentation to make sure my React architecture was clean and stable. Then I gradually scaled with more elements and extended the layout on the viewport through media queries. In the ended the technical part ended up being the easiest."},
        {"id": 2, "paragraph": "The main challenge for this was probably about graphic design and typography. In fact, I wanted to make this as readable as possible due to the amount of text I have and would like to add in the future. Thus I had to research how to best size every aspects of my type, the font I should use with different title styling. Diving into information architecture was also one the things I took for granted. All the content needs to be indexed to be readable by all sorts of users from Blind text to speech engines to social medias and  Google’s search crawlers. In addition, I made some svg visuals including a favicon, a drawing of my face (made in Illustrator) and yellow parallelograms as I felt for esthetic purposes. Lastly, I built a staging server on Heroku to get feedback from my peers before publishing into to the wilderness."}
      ],
      "conclusion": "This project allowed me to advance my skills in front end development in order to prototype evolutive web user interfaces for other projects in the future.",
      "skills": "prototyping, node js, javascript, html, sass, ejs, react, ui, front end design, sketch, adobe illustrator, svg",
      "date": "05.17"
    }
  ],
  "_comment": {
    "id": "",
    "title": "",
    "hero": "",
    "description": "",
    "problem": "",
    "solution": "",
    "addMedia": [
      {"id": "", "url": "", "caption": ""}
    ],
    "conclusion": "",
    "skills": "",
    "team": [
      {"id": "", "name": "", "from": ""}
    ]
  }
}
